---
title: "HW5"
author: "Siyu HEM"
date: "2020/12/5"
output: word_document
---
Load the library
```{r message=FALSE, warning=FALSE}

library(readxl)
library(openxlsx)
library(car)
library(dplyr)
library(ggplot2)
library(scatterplot3d)
library(plotrix)
library(fastDummies)
library(rpart)
library(rpart.plot)
library(party)
library(varImp)
library(forecast)
library(gmodels)
library(FNN)
library(caret)
library(e1071)


```
**Problem 1**

```{r message=FALSE, warning=FALSE}
car <- read_excel("ToyotaCorolla.xlsx", sheet = 2)

car.var <- c(3,4,7,8,9,12,14,17,19,21,25,26,28,30,34,39)
set.seed(1000)

train.index <- sample(row.names(car), 0.5*dim(car)[1])
car.train <- car[train.index, car.var]

rem.index <- setdiff(rownames(car), train.index)
rem.df <- car[rem.index, car.var]

valid.index <- sample(row.names(rem.df), 0.3*dim(car)[1])
car.valid <- car[valid.index, car.var]

test.index <- setdiff(row.names(rem.df), valid.index)
car.test <- car[test.index, car.var]

car <- car[, car.var]
car <- dummy_cols(car)
car <- car[, -4]

car.train <- dummy_cols(car.train)
car.train <- car.train[, -4]

car.valid <- dummy_cols(car.valid)
car.valid <- car.valid[, -4]

car.test <- dummy_cols(car.test)
car.test <- car.test[, -4]

```

**a)**

i)

```{r message=FALSE, warning=FALSE}
car.ct <- rpart(Price ~., data = car, method = "anova",  minsplit = 1, control = rpart.control(maxdepth = 3))
printcp(car.ct)
rpart.plot(car.ct)
prp(car.ct, type = 1, split.font = 2, varlen = -10, extra = 1)

```

The 3 most important car specifications for predicting the car's price are Age_08_04, HP and KM.

ii)

```{r message=FALSE, warning=FALSE}
car.pred.train <- predict(car.ct, car.train)
accuracy(car.pred.train, car.train$Price)

car.pred.test <- predict(car.ct, car.test)
accuracy(car.pred.test, car.test$Price)

car.pred.valid <- predict(car.ct, car.valid)
accuracy(car.pred.valid, car.valid$Price)



```


```{r message=FALSE, warning=FALSE}
boxplot(car.pred.train - car.train$Price, car.pred.test - car.test$Price, car.pred.valid - car.valid$Price,main="Training, Test, Validation data error")

```

From boxplot and RMS error we can see that the training set has the lowest error as it is trained on more number of records. The predictive performance for test set is lower than training test and it is greater than validation set beacuse these are the new records compared to the ones model is trained and validated on.


iv)

```{r message=FALSE, warning=FALSE}
car.model.ct <- rpart(Price ~., data = car.train, method = "anova", cp = 0.00001, minsplit = 5, xval = 5)
car.model.ct.pruned <- prune(car.model.ct, cp = car.model.ct$cptable[which.min(car.model.ct$cptable[,"xerror"]),"CP"]) 
prp(car.model.ct.pruned, type = 1, extra = 1, split.font = 1, varlen = -10)
```


```{r message=FALSE, warning=FALSE}
car.model.ct.pruned.valid <- predict(car.model.ct.pruned, car.valid) 
RMSE(car.model.ct.pruned.valid, car.valid$Price)
```

We can see that pruning the tree has reduced the validation error when compared to the full tree. Hence, the predictive performance is enhanced for the validation set.


**b)**

i)
```{r message=FALSE, warning=FALSE}
car$Pricebin <- as.factor(as.numeric(cut(car$Price, 20))) 

car1 <- car[,-1]

train.index <- sample(row.names(car1), 0.5*dim(car1)[1])
car.train <- car1[train.index,]

rem.index <- setdiff(rownames(car1), train.index)
rem.df <- car1[rem.index, ]

valid.index <- sample(row.names(rem.df), 0.3*dim(car1)[1])
car.valid <- car1[valid.index, ]

test.index <- setdiff(row.names(rem.df), valid.index)
car.test <- car1[test.index, ]
```


```{r message=FALSE, warning=FALSE}
car.model.ct.new <- rpart(Pricebin ~ .,data = car1, method = "class", control = rpart.control(maxdepth = 3)) 
prp(car.model.ct.new, type = 1, extra = 1, split.font = 1, varlen = -10)

```

CT generates more branches than the one generated by RT as it contains more bins. The top predictors are the same. The variable Age_08_04 is still the most important variable in both trees.

```{r message=FALSE, warning=FALSE}
car2 <- data.frame(Age_08_04=77,KM=117000, Fuel_Type_Petrol=1,HP=110, Automatic=0, Doors = 5, Quarterly_Tax=100, Mfr_Guarantee=0, Guarantee_Period=3, Airco=1, Automatic_airco=0, CD_Player=0, Powered_Windows=0, Sport_Model = 0, Tow_Bar = 1, Fuel_Type_CNG=0, Fuel_Type_Diesel = 0)

predict(car.model.ct, car2)
```


```{r message=FALSE, warning=FALSE}
predict(car.model.ct.new, car2)
```


```{r message=FALSE, warning=FALSE}
sum(car[which(car1$Pricebin == 3),1])/dim(car[which(car1$Pricebin == 3),1])[1] - predict(car.model.ct, car2)
```

The difference in magnitude of 2 predictors = 317.5217.

Advantages of these methods:
It performs variable screening or feature selection
It is easy to interpret

Disadvantages of these methods:
It has high complexity
It is time consuming

**Problem 2**

```{r message=FALSE, warning=FALSE}
b <- read_excel("Banks.xlsx")
```

*a)*

```{r message=FALSE, warning=FALSE}
b$`Financial Condition` <- factor(b$`Financial Condition`, levels = c(0,1), labels = c("Strong", "Weak"))
```


```{r message=FALSE, warning=FALSE}
b.m1 <- glm(`Financial Condition` ~ b$`TotLns&Lses/Assets` + b$`TotExp/Assets`, data = b, family=binomial())
b.m1
summary(b.m1)
coef(b.m1)
```

*ii)* 

```{r message=FALSE, warning=FALSE}
exp(coef(b.m1))
```

*iii)*

```{r message=FALSE, warning=FALSE}
b$probability <- predict(b.m1, newdata = b, type="response")
b$probability
```

**b)**

```{r message=FALSE, warning=FALSE}
ndf <- data.frame(`TotLns&Lses/Assets` = .6, `TotExp/Assets`=.11) 
b.m1.val <- predict(b.m1, newdata = ndf, type="response", cl = b$`Financial Condition`)
exp(b.m1.val)

CT <- rpart(`Financial Condition` ~ b$`TotLns&Lses/Assets` + b$`TotExp/Assets`, data = b, method = "class") 
CT.predict <- predict(CT, b, type = "class")
confusionMatrix(CT.predict, b$`Financial Condition`)
```

**c)**

```{r message=FALSE, warning=FALSE}
c.odds <- exp(coefficients(b.m1)[3]) 
c.odds
a <- ifelse(b.m1$fitted.values >= 0.5,0,1) 
table(a, b$`Financial Condition`)
a <- ifelse(b.m1$fitted.values >= 0.9,0,1) 
table(a, b$`Financial Condition`)
a <- ifelse(b.m1$fitted.values >= 0.1,0,1) 
table(a, b$`Financial Condition`)
a <- ifelse(b.m1$fitted.values >= 0,0,1) 
table(a, b$`Financial Condition`)
a <- ifelse(b.m1$fitted.values >= 0.03,0,1) 
table(a, b$`Financial Condition`)
```
In order for the error to be minimum we have to reduce the cutoff value.

**d)**
```{r message=FALSE, warning=FALSE}
fc <- b[which(b$`Financial Condition` == "Weak"),]
sum(fc$`TotExp/Assets`)/sum(fc$`TotLns&Lses/Assets`)
```
 The estimated coefficient for the total loans & leases to total assets ratio(TotLns&Lses/Assets) in terms of the odds of being financially weak is 0.167. Therefore we can classify it as financially strong.

**e)** 

To minimize misclassification the value should be decreased.


**Problem 3**

```{r message=FALSE, warning=FALSE}

sa <- read_excel("System Administrators.xlsx")

```


```{r message=FALSE, warning=FALSE}
sa <- na.omit(sa)
sa.train <- sa

ggplot(sa.train, aes(x = Training, y = Experience, colour = `Completed task`)) + 
  geom_point() + 
  xlab("Training") + 
  ylab("Experience")
```
Experience is the major predictor for the completion of tasks from the plot above. We can see that most of the uncompleted tasks are correlated with an experience of less than 8-9years.There can be a few more parameters which could be taken into consideration in terms of the training(credits attained) for it to be classified as a better predictor.


**b)** 

```{r message=FALSE, warning=FALSE}

sa.train <- sa.train %>% 
  mutate(
    Complete = ifelse(sa$`Completed task` == "Yes", 1, 0)
  )
sa.train <- sa.train[, -3]

sa.mod1 <- glm(Complete ~., data = sa.train, family = "binomial") 
summary(sa.mod1)
data.frame(summary(sa.mod1)$coefficients, odds = exp(coef(sa.mod1))) 
round(data.frame(summary(sa.mod1)$coefficients, odds = exp(coef(sa.mod1))),5)
table(ifelse(sa.mod1$fitted > 0.5, 1, 0), sa.train$Complete)
```
Incorrectly classified as not completing is 33.33%(5/15)

**c)**
 
```{r message=FALSE, warning=FALSE}
z <- ifelse(sa.mod1$fitted.values >= 0.7,1,0) 
table(z, sa$`Completed task`)
```
In order to decrease the incorrectly classified percentage in part b. The cutoff probability should be increased 

 **d)** 

Intercept (B0) = -10.9813
Experience (B1) = 1.1269 
Training (B2) = 0.1805
So, P= (1/(1+e-(B0+B1X1+B2X2)))
X2 =4 (given)
P=0.5
Solving the equation for X1 , we get
0.5= (1/(1+e- (-10.9813+1.1269X1+0.1805(4)))) X1 = 9.11 years
X1 ~ 9 years

For a programmer with 4 years of training to get an estimated probability of completing the task exceeding 50%, almost 9 years of experience is needed.


